## 一、文档更新记录
### 1. 版本信息
- 版本号：v1
- 论文名称：Sample and Computation Redistribution for Efficient Face Detection [CVPR 202105]
- 创建日期：2022.06.08
- 创建人：扶云

## 二、算法介绍
### 1. 核心思想
1. 基于基准数据集统计的样本重新分配(`sr，sample redistribution`) ，它增加了最需要阶段的训练样本;
2. 基于精确定义的搜索方法的计算重新分配(`cr，Computation Redistribution`) ，它在模型的骨干、颈部和头部之间重新分配计算。

> 准确的来说，这里就是考虑直接利用分类网络的主干部分进行特定规模的人脸检测可能是次优的。所以本文提出：参考`regnet`来进行网络搜索，在限定整体模型计算量的情况下，合理的分配每一个 block 的计算量，找到最佳的分配方案；同时，针对特定环节（Stride=8）提升正样本的采样数量来优化模型的训练过程，提升精度。这里有就是前面提到的`计算重分配和样本重分配`。

对于VGA分辨率（640 * 480），大部分wider face的人脸尺寸小于32 * 32，因此采用浅层来进行检测小目标，为了给这些浅层提供更多的训练样本，提出了 采用大裁剪策略的 样本重分布 的方法。

1. 我们探索了VGA分辨率下的人脸检测效率，并提出了一种样本再分配策略(SR)，有助于获得更多的浅阶段训练样本。
2. 我们设计了一个简化的搜索空间，用于人脸检测器的不同组件(主干、颈部和头部)的计算重分配。提出的两步计算再分配方法可以方便地了解计算分配情况。
3. 在WIDER FACE上进行的大量实验表明，在广泛的计算机制中，所提议的SCRFD显著提高了准确性和效率；

### 2. 结论和展望

无


### 3. 实验
#### 数据集介绍
`WIDER FACE`

这里来看一下数据的整体分布情况。

![20220611170823](https://lcv1-1256975222.cos.ap-shanghai.myqcloud.com/20220611170823.png)

图3. 在WIDER FACE验证数据集上的累积人脸比例分布`（简单 ⊂ 中等 ⊂ 困难）`。当长边固定为640像素时，大部分容易的人脸都`大于32×32`，大部分中等的人脸都`大于16×16`。对于困难集，`78.93%的脸小于32×32，51.85%的脸小于16×16，13.36%的脸小于8×8`。


![20220611171046](https://lcv1-1256975222.cos.ap-shanghai.myqcloud.com/20220611171046.png)

使用大裁剪策略后，小面孔（< 32×32）的数量明显增加。

#### 实验结果

### 4. 详细过程

#### 整体思路和考虑

经过缜密的实验，我们对人脸检测的设计提出了以下效率改进，条件是：

- （1）测试规模以VGA分辨率（640）为界限；

- （2）在stride=4的特征图上没有锚点。

特别是，我们在stride=8的特征图上采用{16，32}的锚框，在stride=16采用{64，128}的锚框，在stride=32采用{256，512}的锚框。由于我们的测试规模较小，`大部分人脸将在stride=8的Feature map被预测`。因此，我们首先研究了阳性训练样本在不同尺度的特征图上的再分配情况（第4.1节）。然后，我们探讨了在给定的计算预算下 ==【限定总的计算复杂度】== ，不同尺度的特征图以及不同组件（如骨干、颈部和头部）的计算再分配（第4.2节）。




#### 样本重分配
1. 在现有的setting中，`stride=8处的featuremap 最重要`，所以：希望在这里生成更多的正样本【上面提到困难集上78.93%的脸小于32×32】
2. 在stride=8处，将random size的范围从[0.3, 1.0]提升到[0.3, 2.0]，这样在scale=16处，可以`显著提高正样本的数量（从72.3k->118.3k），在scale=32处（95.9k->115.1k）`，更多的训练样本重新分布到小尺度上，因而对于检测微小人脸可以训练的更充分【裁剪框超出图像的部分补充平均RGB值】
   
#### 计算重分配
> 这块就是网络结构搜索，来重新分配骨干网、颈部和头部的计算。

将搜索方法应用于RetinaNet[18]，以ResNet[12]为骨干，以路径聚合特征金字塔网络（PAFPN）[21]为颈部，以堆叠的3×3卷积层为头部，总的搜索空间还是比较大的。

- A: 第一步探索了骨干部分（即stem[前3个3 * 3卷积层]、C2、C3、C4和C5）内计算的重新分配，同时固定了颈部和头部组件
- B: 第二步基于我们发现的骨干上的优化计算分布，我们进一步探索骨干、颈部和头部之间计算的重新分配

【这里省略如何设计搜索自由度（可变量）的讨论】


简化搜索空间。我们在搜索空间中重复随机抽样，直到我们得到`320个目标复杂度`的模型，并在WIDER FACE训练集上训练`每个模型80个epochs`。然后，我们在验证集上测试每个模型的AP。基于这320对模型的统计数据（xi , APi），其中xi是一个特定组件的计算比率，APi是相应的性能，我们按照[27]计算经验引导法[8]来估计最佳模型可能落在的范围。

最后，为了进一步降低搜索空间的复杂性，我们将网络结构搜索分为以下两个步骤。


- SCRFD1：`只搜索骨干的计算分布`，同时将颈部和头部的设置固定为默认配置。
  - backbone上的计算重分布：由于主干执行大部分计算，我们首先关注主干的结构，它是决定网络计算成本和准确性的核心。`大约80%的计算被重新分配到浅层阶段`【可以看下图，前面3个block的计算量占比】。
  ![20220611173156](https://lcv1-1256975222.cos.ap-shanghai.myqcloud.com/20220611173156.png)
- SCRFD2：搜索`整个face检测器`（即骨干、颈部和头部）的计算分布，骨干内的计算分布遵循优化的SCRFD1。
  - backbone、neck和head的计算重分布：通过使用提出的两步计算重分配方法，我们发现大量的capacity被分配给浅层阶段，backbone最多，head其次，neck最少。使得AP在wider face hard验证集上从74.47%提高到77.87%。【右侧block的宽度对应计算量的多寡】
  ![20220611173558](https://lcv1-1256975222.cos.ap-shanghai.myqcloud.com/20220611173558.png)

- 在更大的计算量和移动端的情况下：对于高计算制度（例如34 Gflops），探索的结构利用了bottleneck 残差块，深度扩展优于浅层阶段的宽度扩展。由于参数增加较多，扩展宽度会出现过度拟合的情况[1]。相比之下，扩展深度，特别是在早期层，与扩展宽度相比，引入的参数更少；对于移动系统（0.5Gflops），将深层阶段的有限容量（如C5）分配给深层阶段捕获的判别性特征，有利于浅层小脸检测。

#### 训练
- 采用了Generalized Focal Loss 和 DIoU loss
- 采用了Adaptive Training Sample Selection (ATSS) 自适应训练样本选择用于正锚框匹配
- 在检测头中，使用了（weight sharing）权重共享和（Group Normalisation）组归一化
- 基于mmdetection开发，采用SGD优化器，Warmup lr（3 epochs），




## 三、附件
[原始论文](https://arxiv.org/abs/2105.04714)

[github](https://github.com/deepinsight/insightface/tree/master/detection/scrfd)

