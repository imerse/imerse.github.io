## 一、文档更新记录
### 1. 版本信息
- 版本号：v1
- 论文名称：SOLOv2: Dynamic and Fast Instance Segmentation [202003CVPR]
- 创建日期：2022.06.12
- 创建人：扶云
## 二、算法介绍
### 1. 核心思想

1. 新框架由`一个高效且整体的实例掩码进行表示`，该方案动态分割图像中的每个实例，而无需借助边界框检测。
2. 使用`矩阵非极大值抑制 (NMS) 技术`显著降低了推理开销。我们的矩阵 NMS 一次性执行具有并行矩阵运算的 NMS，并产生更好的结果。我们证明我们的 SOLOv2 在速度和准确性方面都优于大多数最先进的实例分割方法。轻量级版本在 COCO test-dev 上以 31.3 FPS 的速度执行并产生 37.1% 的 AP。



!!! note
    看起来就是采用了一个直接预测mask的方案，而不需要通过先预测边框再去做分割，第2个就是做了一个矩阵nms加速。
    特点：无proposal、无anchor、类似FCN，速度快

直接看下效果和对比：

![20220613174615](https://lcv1-1256975222.cos.ap-shanghai.myqcloud.com/20220613174615.png)


### 2. 结论和展望
略

### 3. 实验
#### 数据集介绍

1. {++coco 2017++}
2. {++LVIS dataset++}
    LVIS[33]是最近提出的一个用于长尾物体分割的数据集，它有1000多个物体类别。在LVIS中，每个物体实例都是用高质量的掩码来分割的，其质量超过了相关COCO数据集的注释质量。由于LVIS是新的，只有Mask R-CNN的结果是公开的。因此，只将SOLOv2与Mask R-CN基线进行比较。
3. {++COCO2018 的全景分割++}


#### 实验结果
1. SOLOv2比SOLO高出1.9%的AP，同时速度快33%
2. 通过直接将预测的掩码转换为其bbox，产生44.9%的物体检测AP，这甚至超过了许多最先进的、高度工程化的物体检测方法



<figure>
  <img src="https://lcv1-1256975222.cos.ap-shanghai.myqcloud.com/20220613210029.png"  />
  <figcaption>在LVIS dataset上的结果(少、中、多样本，小中大样本集)</figcaption>
</figure>



### 4. 详细过程

我们首先介绍了一个动态方案，该方案能够按位置动态地分割物体。
具体来说，遮罩学习过程可以分为两部分：卷积核学习和特征学习（图2（b））。在将像素划分为不同的位置类别时，掩膜核由网络动态预测，并以输入为条件。我们进一步构建了一个统一的、高分辨率的面具特征表示，用于实例感知的分割。因此，我们能够毫不费力地预测高分辨率的物体掩模，以及单独和有效地学习掩模核和掩模特征。
我们进一步提出了一种高效的矩阵NMS算法。作为抑制重复预测的后处理步骤，非最大抑制（NMS）是最先进的物体检测系统的一个组成部分。以广泛采用的多类NMS为例。对于每个类别，预测按置信度降序排列。然后，对于每个预测，它删除所有其他高度重叠的预测。顺序和递归操作导致了不可忽略的延迟。对于掩码NMS，这一缺点被进一步放大。与边界箱相比，计算每个掩码对的IoU需要更多的时间，从而导致了大量的开销。
我们通过引入Matrix NMS来解决这个问题，Matrix NMS一次就能完成并行矩阵操作的NMS。我们的Matrix NMS在精度和速度上都优于现有的NMS及其品种。结果，Matrix NMS在简单的python实现中，在不到1毫秒的时间内处理了500个掩码，比最近提出的Fast NMS[2]高出0.4% AP

#### 训练策略
### 5. 应用场景
### 6. 附图
## 三、附件